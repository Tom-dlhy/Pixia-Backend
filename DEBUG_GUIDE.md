# ðŸ› DEBUG - Hang et Performance

## ðŸ†˜ ProblÃ¨me identifiÃ©

Le hang "interminable" Ã©tait probablement dÃ» Ã  :

1. **LLM timeout invisible** - Gemini API peut prendre 20-30s sans feedback
2. **Pas de logging** - Impossible de voir oÃ¹ Ã§a pend
3. **asyncio.to_thread sur subprocess** - Peut causer des problÃ¨mes

## âœ… Solutions appliquÃ©es

### 1. Logging massif ajoutÃ©

Tous les appels importants ont du logging DEBUG avec prÃ©fixes clairs:

```python
[LLM-START]       DÃ©but d'une opÃ©ration LLM
[LLM-REQUEST]     Envoi requÃªte Ã  Gemini
[LLM-RESPONSE]    RÃ©ponse reÃ§ue
[LLM-SUCCESS]     OpÃ©ration rÃ©ussie

[KROKI-START]     DÃ©but appel Kroki
[KROKI-EXECUTE]   ExÃ©cution curl
[KROKI-TIMEOUT]   Timeout (10s)
[KROKI-SUCCESS]   SchÃ©ma gÃ©nÃ©rÃ©

[ASYNC-START]     DÃ©but parallelisation
[ASYNC-GATHER]    Attente gather()
[ASYNC-SUCCESS-N] SchÃ©ma N gÃ©nÃ©rÃ©
```

### 2. Timeouts explicites

- **Kroki**: 10s timeout (subprocess)
- **LLM**: DÃ©pend de Gemini (pas controllable)

### 3. Structure de debug amÃ©liorÃ©e

```python
logging.basicConfig(
    level=logging.DEBUG,
    format='[%(levelname)-8s] %(message)s',
    stream=sys.stdout  # Force flush immÃ©diat
)
```

## ðŸ§ª Comment tester

### Option 1: Tests simples (RECOMMANDÃ‰ - rapide)

```bash
# Lance les 4 tests de debug
python3 TEST_DEBUG.py
```

Cela teste:
1. CrÃ©ation CourseSynthesis âœ… (immÃ©diat)
2. LLM seul (10-30s) - peut Ãªtre long
3. LLM async (mÃªme temps)
4. **3 LLM en parallÃ¨le** (gain de ~60%)

### Option 2: Exemples complets (avec Kroki)

```bash
python3 EXAMPLES_USAGE.py
```

DÃ©commentez les exemples async pour tester.

### Option 3: Tests avec timeout

```bash
# Timeout aprÃ¨s 60s
timeout 60 python3 TEST_DEBUG.py
```

## ðŸ“Š Temps attendus

Pour un cours "flash" (1-2 parties):

| Ã‰tape | Temps |
|-------|-------|
| LLM   | 15-30s |
| Kroki (1 schÃ©ma) | 2-5s |
| Kroki (parallelisÃ© 2) | 3-5s (gain!) |

**Total pour 1 cours**: ~20-35s  
**Total pour 3 cours (parallÃ¨le)**: ~25-40s (au lieu de 60-105s!)

## ðŸ” Logs clÃ©s Ã  surveiller

### âœ… Bon flux

```
[INFO] [MAIN] â³ Ã‰TAPE 1/2: GÃ©nÃ©ration contenu + Mermaid (1 appel LLM)...
[DEBUG] [LLM-REQUEST] Envoi requÃªte Ã  Gemini avec timeout...
[DEBUG] [LLM-RESPONSE] RÃ©ponse reÃ§ue, parsing...
[INFO] [LLM-SUCCESS] Cours gÃ©nÃ©rÃ©: 2 parties (Mermaid: 2)
[INFO] [MAIN] â³ Ã‰TAPE 2/2: GÃ©nÃ©ration parallÃ¨le schÃ©mas Mermaid via Kroki...
[DEBUG] [ASYNC-GATHER] Attente de 2 tÃ¢ches en parallÃ¨le...
[INFO] [KROKI-SUCCESS] SchÃ©ma gÃ©nÃ©rÃ©: abc123 (15000 chars base64)
[INFO] [MAIN] âœ…âœ…âœ… GÃ‰NÃ‰RATION COMPLÃ‰TÃ‰E
```

### âš ï¸  ProblÃ¨mes Ã  dÃ©tecter

```
[ERROR] [LLM-GEMINI-ERROR] Erreur Gemini API: timeout
        â†‘ LLM a timeout (probablement quota dÃ©passÃ©)

[ERROR] [KROKI-TIMEOUT] Timeout (10s) lors de l'appel Ã  Kroki
        â†‘ Kroki a Ã©chouÃ© (diagramme trop complexe?)

[ERROR] [KROKI-ERROR] Kroki error (exit 1): ...
        â†‘ Code Mermaid invalide
```

## ðŸ’¡ Si c'est toujours lent

### 1. VÃ©rifier les quotas Gemini

```bash
# Logs Gemini Cloud
gcloud logging read "resource.type=api" --format=json
```

### 2. Tester Kroki directement

```bash
# Test Kroki manuellement
echo "graph TD\nA[Test]" | curl -X POST -H "Content-Type: text/plain" \
  "https://kroki.io/mermaid/svg" --data-binary "@-"
```

### 3. VÃ©rifier le rÃ©seau

```bash
# Ping Kroki
curl -I https://kroki.io
```

## ðŸš€ Optimisations futures

- [ ] Cache Kroki (par hash MD5)
- [ ] Pool de connexions Gemini
- [ ] Batch Kroki (requÃªte groupÃ©e)
- [ ] Local Mermaid rendering (pas Kroki cloud)

## âœ… Checklist debug

- [x] Logging massif ajoutÃ© (DEBUG level)
- [x] Timeouts explicites (10s Kroki)
- [x] asyncio.gather() pour parallelisation
- [x] TEST_DEBUG.py pour tests isolÃ©s
- [x] Flush stdout immÃ©diat (stream=sys.stdout)
- [ ] Tester avec vraie API Gemini
- [ ] Monitorer quotas
- [ ] VÃ©rifier latence rÃ©seau Kroki

## ðŸ“ž Support

Rapportez les logs complets si hang:
```bash
python3 TEST_DEBUG.py 2>&1 | tee debug.log
```

Attachez `debug.log` avec timestamps!
